{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"introduction_tensorflow.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMP9AEuuopb1MPA7Xp8Pj7j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"mzGO0-dK8NGl","executionInfo":{"status":"ok","timestamp":1629038291784,"user_tz":-120,"elapsed":317,"user":{"displayName":"Avinash Singh","photoUrl":"","userId":"13630997326595651938"}}},"source":["import tensorflow as tf\n","# To use the GPU and the TPU, go to the \n","# Edit->Notebook settings -> Hardware accelerator (select GPU/TPU)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kpOvs0V8ocC","executionInfo":{"status":"ok","timestamp":1629038292025,"user_tz":-120,"elapsed":5,"user":{"displayName":"Avinash Singh","photoUrl":"","userId":"13630997326595651938"}}},"source":["# Define layers\n","# 1. Flatten Layer\n","# Flattens the input. Does not affect the batch size.\n","# tf.keras.layers.Flatten(\n","#     data_format=None, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten\n","\n","# 2. Pooling Layers\n","# 2a. AveragePooling1D, MaxPool1D\n","# Downsamples the input representation by taking the average value over the window defined by pool_size\n","# tf.keras.layers.AveragePooling1D(pool_size=2, strides=None, padding='valid',data_format='channels_last', **kwargs) \n","# tf.keras.layers.MaxPool1D(pool_size=2, strides=None, padding='valid',data_format='channels_last', **kwargs) \n","# strides can have integer values\n","# passing can have values \"same\", \"valid\"\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling1D\n","# 2b. AveragePooling2D, MaxPool2D\n","# Downsamples the input along its spatial dimensions (height and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input.\n","# The window is shifted by strides along each dimension.\n","# tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None,**kwargs)\n","# tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None,**kwargs)\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D\n","# 2c. AveragePooling3D, MaxPool3D\n","# Downsamples the input along its spatial dimensions (depth, height, and width) by taking the average value over an input window (of size defined by pool_size)\n","# for each channel of the input\n","# tf.keras.layers.AveragePooling3D(pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None,**kwargs)\n","# tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None,**kwargs)\n","\n","# 3. Convolution Layers\n","# 3a. Conv1D\n","# This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. \n","# If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n","# tf.keras.layers.Conv1D(\n","#     filters, kernel_size, strides=1, padding='valid',\n","#     data_format='channels_last', dilation_rate=1, groups=1,\n","#     activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n","#     bias_initializer='zeros', kernel_regularizer=None,\n","#     bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n","#     bias_constraint=None, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D\n","# 3b. Conv2D\n","# This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. \n","# If use_bias is True, a bias vector is created and added to the outputs.\n","# tf.keras.layers.Conv2D(\n","#     filters, kernel_size, strides=(1, 1), padding='valid',\n","#     data_format=None, dilation_rate=(1, 1), groups=1, activation=None,\n","#     use_bias=True, kernel_initializer='glorot_uniform',\n","#     bias_initializer='zeros', kernel_regularizer=None,\n","#     bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n","#     bias_constraint=None, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n","# 3c. Conv3D\n","# This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. \n","# If use_bias is True, a bias vector is created and added to the outputs\n","# tf.keras.layers.Conv3D(\n","#     filters, kernel_size, strides=(1, 1, 1), padding='valid',\n","#     data_format=None, dilation_rate=(1, 1, 1), groups=1, activation=None,\n","#     use_bias=True, kernel_initializer='glorot_uniform',\n","#     bias_initializer='zeros', kernel_regularizer=None,\n","#     bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n","#     bias_constraint=None, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3D\n","\n","# 4. RNN layers\n","# 4a. LSTM\n","# Long Short-Term Memory layer - Hochreiter 1997.\n","# tf.keras.layers.LSTM(\n","#     units, activation='tanh', recurrent_activation='sigmoid',\n","#     use_bias=True, kernel_initializer='glorot_uniform',\n","#     recurrent_initializer='orthogonal',\n","#     bias_initializer='zeros', unit_forget_bias=True,\n","#     kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,\n","#     activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,\n","#     bias_constraint=None, dropout=0.0, recurrent_dropout=0.0,\n","#     return_sequences=False, return_state=False, go_backwards=False, stateful=False,\n","#     time_major=False, unroll=False, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n","# 4b. Bidirectional\n","# Bidirectional wrapper for RNNs.\n","# tf.keras.layers.Bidirectional(\n","#     layer, merge_mode='concat', weights=None, backward_layer=None,\n","#     **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional\n","\n","# 5. Dense layers\n","# Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, \n","# kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True). \n","# tf.keras.layers.Dense(\n","#     units, activation=None, use_bias=True,\n","#     kernel_initializer='glorot_uniform',\n","#     bias_initializer='zeros', kernel_regularizer=None,\n","#     bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n","#     bias_constraint=None, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n","\n","# 6. Batch Normalization\n","# Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\n","# tf.keras.layers.BatchNormalization(\n","#     axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n","#     beta_initializer='zeros', gamma_initializer='ones',\n","#     moving_mean_initializer='zeros',\n","#     moving_variance_initializer='ones', beta_regularizer=None,\n","#     gamma_regularizer=None, beta_constraint=None, gamma_constraint=None, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n","\n","# 7. Dropout\n","# The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n","# tf.keras.layers.Dropout(\n","#     rate, noise_shape=None, seed=None, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"GurBTw_XI3vl","executionInfo":{"status":"ok","timestamp":1629038292025,"user_tz":-120,"elapsed":5,"user":{"displayName":"Avinash Singh","photoUrl":"","userId":"13630997326595651938"}}},"source":["# Activation Functions\n","# 1. Linear Activation\n","# Linear activation function (pass-through).\n","# tf.keras.activations.linear(\n","#     x\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear\n","\n","# 2. RELU\n","# Applies the rectified linear unit activation function.\n","# With default values, this returns the standard ReLU activation: max(x, 0), the element-wise maximum of 0 and the input tensor.\n","# tf.keras.activations.relu(\n","#     x, alpha=0.0, max_value=None, threshold=0\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu\n","\n","# 3. Sigmoid\n","# Sigmoid activation function, sigmoid(x) = 1 / (1 + exp(-x)).\n","# Applies the sigmoid activation function. For small values (<-5), sigmoid returns a value close to zero, and for large values (>5) the result of the function gets close to 1.\n","# tf.keras.activations.sigmoid(\n","#     x\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid\n","\n","# 4. Softmax\n","# Softmax converts a vector of values to a probability distribution.\n","# The elements of the output vector are in range (0, 1) and sum to 1.\n","# tf.keras.activations.softmax(\n","#     x, axis=-1\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax\n","\n","# 5. TANH\n","# Hyperbolic tangent activation function.\n","# The elements of the output vector are in range (-1, +1).\n","# tf.keras.activations.tanh(\n","#     x\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"DY8_7xxZI6cI","executionInfo":{"status":"ok","timestamp":1629038292025,"user_tz":-120,"elapsed":4,"user":{"displayName":"Avinash Singh","photoUrl":"","userId":"13630997326595651938"}}},"source":["# Models\n","# Define the model\n","# 1. Making the sequential model\n","# Sequential groups a linear stack of layers into a tf.keras.Model.\n","# Create a model\n","# tf.keras.Sequential(\n","#     layers=None, name=None\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n","\n","# 2. Making the custom model (parallel, distributed etc)\n","# Model groups layers into an object with training and inference features\n","# tf.keras.Model(\n","#     *args, **kwargs\n","# )\n","# Reference: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n","\n","# To visualize the model architecture\n","# model.summary()"],"execution_count":10,"outputs":[]}]}